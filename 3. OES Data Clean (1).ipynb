{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Source of BLS data: https://www.bls.gov/oes/tables.htm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "We have occupation employment numbers from the Bureau of Labor Statistics by metropolitan areas, but both our maps and CO2 emission factors are in zip code. \n",
    "\n",
    "Here we come up with a mapping of metropolitan and non-metropolitan areas listed in the BLS data set to zip code. \n",
    "\n",
    "We start by using a mapping of zip code to MSA provided by the Bureau of Labor Statisics. This works for most major metropolitan areas. Non-metropolitan areas, however, are not listed. In those cases, we maps zips that have not been assigned to an MSA to the sum of all non-metropolitan areas in that state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to turn strings into a floating point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_flt(x):\n",
    "    o = re.search('^[0-9\\.]*$',str(x))\n",
    "    if o:\n",
    "        out = float(str(x))\n",
    "    else:\n",
    "        out = np.nan\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to cull the zips in the DOL data set because it turns out they use postal zip codes as opposed to zip code tabulaton area (ZTCA) which is what we will need in R. In general, there is a pretty good one-to-one correspondance between the two. Here we will drop ZIPs that are not in our ZTCA data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in zips that are present in our R choropleth mapping object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zips = pd.read_csv('Datasets/zips.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the set of zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zips_in_r_set = set(zips['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the mappings of zip to MSA that we have from DOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa_og = pd.read_excel('Datasets/fs15_gpci_by_msa-ZIP.xls', sheet_name = 'fs15gpci by ZIP, owcp', skiprows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop some of the columns we will not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa_og.drop(['GPCI','GPCI.1','GPCI.2','Unnamed: 8'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't need Puerto Rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa_og = zip_to_msa_og[zip_to_msa_og['STATE'] != 'PR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the set of zips in the DOL data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zips_w_msas_set = set(zip_to_msa_og['ZIP CODE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the intersection of zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zips_inter = list(zips_w_msas_set.intersection(zips_in_r_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_zips = pd.DataFrame({'zip':zips_inter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a merge to get the subset of elements in our DOL dataset that have an element in our mapping object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa = pd.merge(good_zips,zip_to_msa_og,left_on='zip',right_on = 'ZIP CODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop and sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa.drop('zip',axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#zip_to_msa.sort(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa['id'] = zip_to_msa.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's start reading in data from BLS. First we are going to read in data for metropolitan areas.\n",
    "\n",
    "i.e., Add the mapping of MSA to zipcode in MSA_M(year)_dl.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### --- 2012\n",
    "a = pd.read_excel('Datasets/oesm12ma/MSA_M2012_dl_1_AK_IN.xls',sheet_name='MSA_dl_1')\n",
    "b = pd.read_excel('Datasets/oesm12ma/MSA_M2012_dl_2_KS_NY.xls',sheet_name='MSA_dl_2')\n",
    "c = pd.read_excel('Datasets/oesm12ma/MSA_M2012_dl_3_OH_WY.xls',sheet_name='MSA_dl_3')\n",
    "oes = pd.concat([a,b,c], axis=0)\n",
    "### ---\n",
    "\n",
    "#oes = pd.read_excel('Datasets/oesm14ma/MSA_M2014_dl.xlsx',sheet_name='MSA_dl')\n",
    "#oes = pd.read_excel('Datasets/oesm17ma/MSA_M2017_dl.xlsx',sheet_name='MSA_dl_1')\n",
    "#oes = pd.read_excel('Datasets/oesm18ma/MSA_M2018_dl.xlsx',sheet_name='MSA_dl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = oes.columns[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oes_lite = oes[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nuoaleon/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "#oes_lite['TOT_EMP'] = oes_lite['TOT_EMP'].apply(make_flt)\n",
    "oes_lite.loc[:, 'TOT_EMP'] = oes_lite['TOT_EMP'].apply(make_flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a merge with our zip_to_msa dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out1 = pd.merge(zip_to_msa, oes_lite, left_on='MSA No.',right_on='AREA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to read in data from \"aggregated\" MSA regions that were broken out into smaller regions in the above dataset. We are then going to do a merge on our zip_to_msa dataframe\n",
    "\n",
    "i.e., Add the mapping of MSA to zipcode in aMSA_M(year)_dl.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oes2 = None\n",
    "\n",
    "try:\n",
    "    oes2 = pd.read_excel('Datasets/oesm12ma/aMSA_M2012_dl.xls',sheet_name='AMSA_dl')\n",
    "    #oes2 = pd.read_excel('Datasets/oesm14ma/aMSA_M2014_dl.xlsx',sheet_name='AMSA_dl')\n",
    "    #oes2 = pd.read_excel('Datasets/oesm17ma/aMSA_M2017_dl.xlsx',sheet_name='AMSA_dl')\n",
    "    #oes2 = pd.read_excel('Datasets/oesm18ma/aMSA_M2018_dl.xlsx',sheet_name='AMSA_dl')\n",
    "except FileNotFoundError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if oes2 is not None:\n",
    "    oes_lite2 = oes2[cols]\n",
    "else:\n",
    "    oes_lite2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nuoaleon/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "if oes_lite2 is not None:\n",
    "    #oes_lite2['TOT_EMP'] = oes_lite2['TOT_EMP'].apply(make_flt)\n",
    "    oes_lite2.loc[:, 'TOT_EMP'] = oes_lite2['TOT_EMP'].apply(make_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if oes_lite2 is not None:\n",
    "    out2 = pd.merge(zip_to_msa, oes_lite2,left_on='MSA No.',right_on='AREA')\n",
    "else:\n",
    "    out2 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next there are a couple of MSAs whose names are out of date in the zip_to_msa dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nuoaleon/opt/anaconda3/lib/python3.7/site-packages/openpyxl/worksheet/_reader.py:296: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "df_updated_msas = pd.read_excel('Datasets/Updated MSAs.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out which metropolitan areas are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_zips = set(zip_to_msa.index)\n",
    "\n",
    "if out2 is not None:\n",
    "    msa_zips = set(out1.id.values).union(set(out2.id.values))\n",
    "else:\n",
    "    msa_zips = set(out1.id.values)\n",
    "\n",
    "missing_zips = list(all_zips.difference(msa_zips))\n",
    "df_missing_zips = zip_to_msa.loc[missing_zips,:]\n",
    "metro_missing = ~df_missing_zips['MSA Name'].str.contains('NONMETRO')\n",
    "df_metro_missing = df_missing_zips.loc[metro_missing,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge with the dataframe that has updated MSA names\n",
    "\n",
    "\n",
    "i.e., get a mapping from old MSA to new MSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa_new = pd.merge(df_metro_missing,df_updated_msas.loc[:,['Old MSA','New MSA']],left_on = 'MSA No.',right_on = 'Old MSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zip_to_msa_new.drop(['MSA No.','Old MSA'],axis=1,inplace = True)\n",
    "zip_to_msa_new.rename(columns = {'New MSA':'MSA No.'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if oes_lite2 is not None:\n",
    "    oes_lite3 = pd.concat([oes_lite, oes_lite2], axis=0)\n",
    "else:\n",
    "    oes_lite3 = oes_lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#out3 = pd.merge(zip_to_msa_new, oes_lite, left_on='MSA No.',right_on='AREA')\n",
    "out3 = pd.merge(zip_to_msa_new, oes_lite3, left_on='MSA No.',right_on='AREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_zips = set(zip_to_msa.index)\n",
    "\n",
    "if out2 is not None:\n",
    "    msa_zips = (set(out1.id.values).union(set(out2.id.values))).union(set(out3.id.values))\n",
    "else:\n",
    "    msa_zips = set(out1.id.values).union(set(out3.id.values))\n",
    "\n",
    "missing_zips = list(all_zips.difference(msa_zips))\n",
    "df_missing_zips = zip_to_msa.loc[missing_zips,:]\n",
    "metro_missing = ~df_missing_zips['MSA Name'].str.contains('NONMETRO')\n",
    "df_metro_missing = df_missing_zips.loc[metro_missing,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to assign all remaining non-metro zips to the non-metro data\n",
    "\n",
    "i.e., Add the mapping of Non-MSA to zipcode in BOS_M(year)_dl.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oes3 = pd.read_excel('Datasets/oesm12ma/BOS_M2012_dl.xls',sheet_name='BOS_dl_1')\n",
    "#oes3 = pd.read_excel('Datasets/oesm14ma/BOS_M2014_dl.xlsx',sheet_name='BOS_dl')\n",
    "#oes3 = pd.read_excel('Datasets/oesm17ma/BOS_M2017_dl.xlsx',sheet_name='BOS_dl_1')\n",
    "#oes3 = pd.read_excel('Datasets/oesm18ma/BOS_M2018_dl.xlsx',sheet_name='BOS_dl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in oes3.columns[6:]:\n",
    "    oes3[col] = oes3[col].apply(make_flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oes_lite3 = oes3[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oes_lite3 = oes_lite3.groupby(['PRIM_STATE','OCC_TITLE','OCC_CODE','OCC_GROUP']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oes_lite3['AREA_NAME'] = oes_lite3['PRIM_STATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out4 = pd.merge(df_missing_zips, oes_lite3, left_on = 'STATE',right_on='PRIM_STATE')\n",
    "## Since here we join it using STATE, do we need to re-weight the TOP_EMP by zipcode count inside that state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oes_lite3.head()\n",
    "# out4[out4['ZIP CODE'] == 99547].head()\n",
    "# out4[out4['ZIP CODE'] == 99546].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if out2 is not None:\n",
    "    out = pd.concat([out1,out2,out3[out1.columns],out4[out1.columns]],axis=0,ignore_index=True)\n",
    "else:\n",
    "    out = pd.concat([out1,out3[out1.columns],out4[out1.columns]],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out.drop(['PRIM_STATE','MSA Name','County No.','AREA'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#out.sort('id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to write our data-set out as a SQL database to make it a little easier to access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_db(df,db):  \n",
    "    '''\n",
    "    Write dataframe to database. Assume we are appending to a database\n",
    "    '''\n",
    "    con = sqlite3.connect(db)\n",
    "    df.to_sql('data',con,if_exists = 'replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nuoaleon/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2882: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "# write_db(out,'Datasets/oes_may12_demo.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
