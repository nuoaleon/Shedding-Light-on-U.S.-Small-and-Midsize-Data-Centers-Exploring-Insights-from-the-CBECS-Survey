{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data and also match PBA code to it's actual name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample that reported with rack: 1715\n",
      "number of sample that reported with server: 1918\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "## 2018\n",
    "df = pd.read_csv('Datasets/CBECS2018/cbecs2018_final_public.csv',header=0,index_col=0)\n",
    "df['RACKN'] = df['SERVERN'].copy()\n",
    "df.loc[df['SRVUNIT'] == 2, 'SERVERN'] = float('nan')\n",
    "df.loc[df['SRVUNIT'] == 1, 'RACKN'] = float('nan')\n",
    "# ----------------------------------------------------------------------------------- #\n",
    "\n",
    "print(\"number of sample that reported with rack: %d\" % df['RACKN'].count())\n",
    "print(\"number of sample that reported with server: %d\" % df['SERVERN'].count())\n",
    "\n",
    "pba_id = pd.read_csv('pba_id.csv',header=0,index_col=0)\n",
    "pbaplus_id = pd.read_csv('pbaplus_id.csv', header = 0, index_col = 0)\n",
    "df = df.join(pba_id,on='PBA')\n",
    "df = df.join(pbaplus_id,on = 'PBAPLUS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize each building based on the number of servers/racks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "# Inclusive:\n",
    "order = type = ['small','midsize','large']\n",
    "\n",
    "# Server number by DC size # -- assumptions for 2012 data\n",
    "defs = [(1,25,'small'),\n",
    "        (26,499,'midsize'),\n",
    "        (500,1e5,'large')]\n",
    "\n",
    "# Server number per rack # \n",
    "avg_servers_per_rack = {'small': 0.75,\n",
    "                    'midsize': 3, \n",
    "                    'large': 10}\n",
    "\n",
    "# Rack number\n",
    "tmp = []\n",
    "for l, h, t in defs:\n",
    "    tmp.append([l/avg_servers_per_rack[t], h/avg_servers_per_rack[t], t])\n",
    "\n",
    "tmp[2][0] += 0.0001\n",
    "defs2 = []\n",
    "for i in range(len(tmp)):\n",
    "    if i == 0:\n",
    "        l, h = min(tmp[i][0], 1), math.floor(min(tmp[i][1], tmp[i+1][0]))\n",
    "        defs2.append([l, h, tmp[i][2]])\n",
    "    elif i == len(tmp) - 1:\n",
    "        l, h = math.ceil(max(tmp[i][0], tmp[i-1][1])), tmp[i][1]\n",
    "        defs2.append([l, h, tmp[i][2]])\n",
    "    else:\n",
    "        l1, h1 = math.ceil(min(tmp[i][0], tmp[i-1][1])), math.floor(max(tmp[i][0], tmp[i-1][1]))\n",
    "        defs2.append([l1, h1,  tmp[i-1][2] + \"/\" + tmp[i][2]])\n",
    "\n",
    "        l, h = math.ceil(max(tmp[i-1][1], tmp[i][0])), math.floor(min(tmp[i+1][0], tmp[i][1]))\n",
    "        defs2.append([l, h, tmp[i][2]])\n",
    "\n",
    "        l2, h2 = math.ceil(min(tmp[i][1], tmp[i+1][0])), math.floor(max(tmp[i][1], tmp[i+1][0]))\n",
    "        defs2.append([l2, h2,  tmp[i][2] + \"/\" + tmp[i+1][2]])\n",
    "# ----------------------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server number by DC size: [(1, 25, 'small'), (26, 499, 'midsize'), (500, 100000.0, 'large')]\n",
      "Rack number by DC size: [[1, 8, 'small'], [9, 33, 'small/midsize'], [34, 50, 'midsize'], [51, 166, 'midsize/large'], [167, 10000.0, 'large']]\n",
      "avg_servers_per_rack: {'small': 0.75, 'midsize': 3, 'large': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Server number by DC size: {}'.format(defs))\n",
    "print('Rack number by DC size: {}'.format(defs2))\n",
    "print('avg_servers_per_rack: {}'.format(avg_servers_per_rack))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['space type'] = np.nan\n",
    "for tup in defs:\n",
    "    m = (df['SERVERN'] <= tup[1]) & (df['SERVERN']>= tup[0])\n",
    "    df.loc[m,'space type'] = tup[2]\n",
    "\n",
    "for tup in defs2:\n",
    "    m = (df['RACKN'] <= tup[1]) & (df['RACKN']>= tup[0])\n",
    "    df.loc[m,'space type'] = tup[2]\n",
    "\n",
    "# Check to make sure we didn't miss any buildings\n",
    "df['space type'].dropna().count() == (df['RACKN'].count() + df['SERVERN'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambigous classifications:  493\n",
      "Ambigous classifications:  306\n",
      "Ambigous classifications:  67\n",
      "Ambigous classifications:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Ambigous classifications: \",  len(df[df['space type'].isin({'midsize/large', 'small/midsize'})]))\n",
    "\n",
    "# Further classify ambigous 'space type' based on \"Data center sqft category\" column \n",
    "df.loc[df['space type'].isin({'small/midsize'}) & df['DCNTRSFC'] == 1, 'space type'] = 'small' # 1=500 square feet or less\n",
    "df.loc[df['space type'].isin({'midsize/large', 'small/midsize'}) & df['DCNTRSFC'] == 3, 'space type'] = 'midsize' # 3=1,501 to 3,000 square feet\n",
    "df.loc[df['space type'].isin({'midsize/large', 'small/midsize'}) & df['DCNTRSFC'] == 4, 'space type'] = 'midsize' # 4=3,001 to 10,000 square feet\n",
    "\n",
    "print(\"Ambigous classifications: \", + len(df[df['space type'].isin({'midsize/large', 'small/midsize'})]))\n",
    "\n",
    "# Further classify ambigous 'space type' based on \"Server closet\" column: if survey indicate this sample to be \"Server closet\", classify as small\n",
    "df.loc[df['space type'].isin({'small/midsize'}) & df['SRVRCLST'] == 1, 'space type'] = 'small'\n",
    "\n",
    "print(\"Ambigous classifications: \", + len(df[df['space type'].isin({'midsize/large', 'small/midsize'})]))\n",
    "# Further classify ambigous 'space type' based on \"SQFT\" column: calculate the mapping of 'space type' to average 'SQFT' based on data that is not ambigous, then assign the classification based on cloest distance\n",
    "def map_space_type_mid_or_large(sqft):\n",
    "    mapping = df[~df['space type'].isin({'midsize/large', 'small/midsize'})].groupby('space type')['SQFT'].mean().to_dict()\n",
    "    del mapping['small']\n",
    "    closest_category = min(mapping, key=lambda x: abs(mapping[x] - sqft))\n",
    "    return closest_category\n",
    "\n",
    "df.loc[df['space type'].isin({'midsize/large'}), 'space type'] = df.loc[df['space type'].isin({'midsize/large'}), 'SQFT'].apply(map_space_type_mid_or_large)\n",
    "\n",
    "print(\"Ambigous classifications: \", + len(df[df['space type'].isin({'midsize/large', 'small/midsize'})]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For samples reported with rack, get server number by rack number * avg_servers_per_rack;\n",
    "Similarly for samples reported with server;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['SRVUNIT'] == 2, 'SERVERN'] = df.loc[df['SRVUNIT'] == 2, 'RACKN'] * df.loc[df['SRVUNIT'] == 2, 'space type'].map(avg_servers_per_rack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['SRVUNIT'] == 1, 'RACKN'] = df.loc[df['SRVUNIT'] == 1, 'SERVERN'] / df.loc[df['SRVUNIT'] == 1, 'space type'].map(avg_servers_per_rack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of server samples after imputation: 3633\n",
      "number of rack samples after imputation: 3633\n"
     ]
    }
   ],
   "source": [
    "print(\"number of server samples after imputation: %d\" % df['SERVERN'].count())\n",
    "print(\"number of rack samples after imputation: %d\" % df['RACKN'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply building weight by the number of racks/servers in each building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nweight_s'] = df['SERVERN']*df['FINALWT']\n",
    "df['nweight_r'] = df['RACKN']*df['FINALWT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code DATACNTR column as either true or false. Note that specifically refers to whether something is a data center of farm. So data rooms and closets are coded as false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_dc = df['DATACNTR'] == 1\n",
    "\n",
    "df.loc[m_dc,'DATACNTR'] = True\n",
    "df.loc[~m_dc,'DATACNTR'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map coded values for server square footage to their actual ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_map = {1:'<= 500 sq. ft.',\n",
    "            2:'501 to 1500 sq. ft.',\n",
    "            3:'1501 to 3000 sq. ft.',\n",
    "            4:'3001 to 10,000 sq. ft.',\n",
    "            5:'> 10,000 sq. ft.',\n",
    "            0:np.nan}\n",
    "df.loc[df['DCNTRSFC'].isnull(),'DCNTRSFC'] = 0\n",
    "df['data center sq. ft.'] = df.DCNTRSFC.apply(lambda x:data_map[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's replace 9995 values in SERVERN with something more representative based on the expected total number of shipments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5323.79191542552\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "# tot_serv = 13581642.   #From 2012 value.\n",
    "tot_serv = 16832576.   #From 2018 value: the calculation below not appliable to 2018 data (due to server rack, leave it here for later modification/extended analysis)\n",
    "# ----------------------------------------------------------------------------------- #\n",
    "\n",
    "m = df['SERVERN'] > defs[2][0] # filter out 'large'/ 'Service Provider'\n",
    "avg_num_he_s = (tot_serv - df.loc[~m,'nweight_s'].sum())/df.loc[m,'FINALWT'].sum()\n",
    "print(avg_num_he_s)\n",
    "df.loc[m,'SERVERN'] = avg_num_he_s\n",
    "df.loc[m,'nweight_s'] = avg_num_he_s*df.loc[m,'FINALWT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, do this for rack column\n",
    "df.loc[m,'RACKN'] = avg_num_he_s/avg_servers_per_rack[defs[2][2]]\n",
    "df.loc[m,'nweight_r'] = (avg_num_he_s/avg_servers_per_rack[defs[2][2]])*df.loc[m,'FINALWT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check to make sure that the total number of servers matches tot_serv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['nweight_s'].sum() == tot_serv) or (abs(df['nweight_s'].sum() - tot_serv) <= 10**(-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nweight_s'].sum() == (df['nweight_r'] * df['space type'].map(avg_servers_per_rack)).sum() or (abs(df['nweight_s'].sum() - (df['nweight_r'] * df['space type'].map(avg_servers_per_rack)).sum()) <= 10**(-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------- #\n",
    "\n",
    "# df.to_csv('Datasets/cbecs_servers_cleaned_2018_dummy.csv')\n",
    "\n",
    "# ----------------------------------------------------------------------------------- #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
